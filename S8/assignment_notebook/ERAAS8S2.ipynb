{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "NIfekP8fg7dy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dfx4fJgOg0KR"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformations"
      ],
      "metadata": {
        "id": "9jDjKvS5g_Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomRotation(15),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                                       ])\n"
      ],
      "metadata": {
        "id": "L_j_-IKog9jP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Creating Train/Test Split"
      ],
      "metadata": {
        "id": "-3dMspzThDme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the CIFAR-10 training dataset\n",
        "train = datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu2rD835hBVs",
        "outputId": "0a6a131b-0599-4821-c19e-8ee5772941bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29377187.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders"
      ],
      "metadata": {
        "id": "GHepeyQ-hH1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLaUYKFxhFvI",
        "outputId": "9c62e53d-71e1-41ab-9c1f-7bcd12a2839e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Statistics"
      ],
      "metadata": {
        "id": "XxS_84BHhMBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "import torchvision\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "m0S7tvvnhKCH",
        "outputId": "7c9c9f67-e6db-4649-cfda-b753bcabe4f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ship  bird  cat   dog  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model"
      ],
      "metadata": {
        "id": "uypP_iPLhP8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "dropout_value = 0.1\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(7, 7), padding=3, bias=False),\n",
        "            nn.ReLU(),\n",
        "            # Define your Group Normalization layers\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 26\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 24\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )  # output_size = 24\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # output_size = 12\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 10\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 8\n",
        "\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # output_size = 12\n",
        "\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 10\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 8\n",
        "\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(8, 32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )  # output_size = 6\n",
        "\n",
        "\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        )  # output_size = 1\n",
        "\n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = x + self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock10(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)\n"
      ],
      "metadata": {
        "id": "kINd7e81hNso"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Params"
      ],
      "metadata": {
        "id": "GKl18kNIi0Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3,32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-86tCgwiua8",
        "outputId": "f1669064-f510-4347-99d8-ef62a55ed82c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]           4,704\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "         GroupNorm-3           [-1, 32, 32, 32]              64\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           9,216\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "         GroupNorm-7           [-1, 32, 32, 32]              64\n",
            "           Dropout-8           [-1, 32, 32, 32]               0\n",
            "            Conv2d-9           [-1, 16, 32, 32]             512\n",
            "        MaxPool2d-10           [-1, 16, 16, 16]               0\n",
            "           Conv2d-11           [-1, 32, 16, 16]           4,608\n",
            "             ReLU-12           [-1, 32, 16, 16]               0\n",
            "        GroupNorm-13           [-1, 32, 16, 16]              64\n",
            "          Dropout-14           [-1, 32, 16, 16]               0\n",
            "           Conv2d-15           [-1, 32, 16, 16]           9,216\n",
            "             ReLU-16           [-1, 32, 16, 16]               0\n",
            "        GroupNorm-17           [-1, 32, 16, 16]              64\n",
            "          Dropout-18           [-1, 32, 16, 16]               0\n",
            "           Conv2d-19           [-1, 16, 16, 16]             512\n",
            "        MaxPool2d-20             [-1, 16, 8, 8]               0\n",
            "           Conv2d-21             [-1, 32, 8, 8]           4,608\n",
            "             ReLU-22             [-1, 32, 8, 8]               0\n",
            "        GroupNorm-23             [-1, 32, 8, 8]              64\n",
            "          Dropout-24             [-1, 32, 8, 8]               0\n",
            "           Conv2d-25             [-1, 32, 8, 8]           9,216\n",
            "             ReLU-26             [-1, 32, 8, 8]               0\n",
            "        GroupNorm-27             [-1, 32, 8, 8]              64\n",
            "          Dropout-28             [-1, 32, 8, 8]               0\n",
            "           Conv2d-29             [-1, 32, 8, 8]           9,216\n",
            "             ReLU-30             [-1, 32, 8, 8]               0\n",
            "        GroupNorm-31             [-1, 32, 8, 8]              64\n",
            "          Dropout-32             [-1, 32, 8, 8]               0\n",
            "        AvgPool2d-33             [-1, 32, 1, 1]               0\n",
            "           Conv2d-34             [-1, 10, 1, 1]             320\n",
            "================================================================\n",
            "Total params: 52,576\n",
            "Trainable params: 52,576\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.88\n",
            "Params size (MB): 0.20\n",
            "Estimated Total Size (MB): 3.10\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing"
      ],
      "metadata": {
        "id": "LG3z6WuIi8d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "metadata": {
        "id": "hApZAtMii2BE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Train and test our model"
      ],
      "metadata": {
        "id": "1evp1xoIjANm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "EPOCHS = 21\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # scheduler.step()\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHe9f7t3i-I9",
        "outputId": "e4134698-82c7-4c84-edf0-fb79a1969be7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/98 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loss=1.6905739307403564 Batch_id=97 Accuracy=27.55: 100%|██████████| 98/98 [00:31<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7021, Accuracy: 3706/10000 (37.06%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.5510135889053345 Batch_id=97 Accuracy=39.26: 100%|██████████| 98/98 [00:30<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4827, Accuracy: 4610/10000 (46.10%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.5205405950546265 Batch_id=97 Accuracy=44.21: 100%|██████████| 98/98 [00:31<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4125, Accuracy: 4844/10000 (48.44%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.4255120754241943 Batch_id=97 Accuracy=48.44: 100%|██████████| 98/98 [00:31<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2988, Accuracy: 5269/10000 (52.69%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.454236388206482 Batch_id=97 Accuracy=51.48: 100%|██████████| 98/98 [00:30<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3091, Accuracy: 5247/10000 (52.47%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.2329893112182617 Batch_id=97 Accuracy=53.26: 100%|██████████| 98/98 [00:33<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2133, Accuracy: 5606/10000 (56.06%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.185590147972107 Batch_id=97 Accuracy=55.19: 100%|██████████| 98/98 [00:30<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.1656, Accuracy: 5796/10000 (57.96%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0825368165969849 Batch_id=97 Accuracy=57.25: 100%|██████████| 98/98 [00:32<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.1443, Accuracy: 5889/10000 (58.89%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0117107629776 Batch_id=97 Accuracy=59.15: 100%|██████████| 98/98 [00:31<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0626, Accuracy: 6216/10000 (62.16%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1785008907318115 Batch_id=97 Accuracy=60.15: 100%|██████████| 98/98 [00:31<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0036, Accuracy: 6377/10000 (63.77%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.051694631576538 Batch_id=97 Accuracy=60.97: 100%|██████████| 98/98 [00:32<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0452, Accuracy: 6333/10000 (63.33%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1978280544281006 Batch_id=97 Accuracy=62.24: 100%|██████████| 98/98 [00:30<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0468, Accuracy: 6299/10000 (62.99%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0216946601867676 Batch_id=97 Accuracy=62.80: 100%|██████████| 98/98 [00:32<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9307, Accuracy: 6700/10000 (67.00%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.113516926765442 Batch_id=97 Accuracy=63.98: 100%|██████████| 98/98 [00:31<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9290, Accuracy: 6710/10000 (67.10%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9256383776664734 Batch_id=97 Accuracy=64.78: 100%|██████████| 98/98 [00:31<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9045, Accuracy: 6827/10000 (68.27%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9828906059265137 Batch_id=97 Accuracy=65.89: 100%|██████████| 98/98 [00:31<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9073, Accuracy: 6817/10000 (68.17%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9594274163246155 Batch_id=97 Accuracy=65.94: 100%|██████████| 98/98 [00:31<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8580, Accuracy: 6968/10000 (69.68%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.934554398059845 Batch_id=97 Accuracy=66.67: 100%|██████████| 98/98 [00:32<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8496, Accuracy: 7035/10000 (70.35%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8697504997253418 Batch_id=97 Accuracy=67.21: 100%|██████████| 98/98 [00:31<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8778, Accuracy: 6893/10000 (68.93%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9097899198532104 Batch_id=97 Accuracy=67.59: 100%|██████████| 98/98 [00:31<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8197, Accuracy: 7100/10000 (71.00%)\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9220667481422424 Batch_id=97 Accuracy=68.10: 100%|██████████| 98/98 [00:30<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8303, Accuracy: 7104/10000 (71.04%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target\n",
        "  1. Make this network:\n",
        "\n",
        "      a) C1 C2 c3 P1 C3 C4 C5 c6 P2 C7 C8 C9 GAP C10\n",
        "\n",
        "      b) Keep the parameter count less than 50000\n",
        "\n",
        "      c) Try and add one layer to another\n",
        "\n",
        "      d) Max Epochs is 20\n",
        "\n",
        "Result\n",
        "  1. Out Best Training accuracy was 68.10 %\n",
        "  2. Out Best Testing accuracy was 71.04 %\n",
        "\n",
        "Analysis\n",
        "  1. We can still see the underfitting\n",
        "  2. We have use Group Normalization\n",
        "  3. After using Group Normalization, we can see that there is drop in both train & test accuracy as compared to Batch Normalization"
      ],
      "metadata": {
        "id": "5py3o1Mjl60w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTMYE3JwjCAj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}